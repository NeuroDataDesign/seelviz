{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ilastik for 10/31/16 Week\n",
    "From last week, I was able to generate 3D TIFF slices and image classifiers on Fear199 downsampled data.  However, my problems were that:  \n",
    "1)  The TIFF slices were odd, cigar-shaped tubes.  \n",
    "2)  I was unable to generate a significant classifier using the existing data because of the weird image layout.  \n",
    "\n",
    "What I did this week was:  \n",
    "1)  Figure out why my original data was the odd cigar-shaped data.    \n",
    "2)  Correctly generate a subset of TIFF slices for Fear199.   \n",
    "3)  Generate a pixel-based object classifier following the guide here:   http://ilastik.org/documentation/counting/counting  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Why was my original data cigar-shaped?  \n",
    "When downloading the image from ndreg, there were two different approaches to generating the numpy array.  I've shown both below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Script used to download nii run on Docker\n",
    "from ndreg import *\n",
    "import matplotlib\n",
    "import ndio.remote.neurodata as neurodata\n",
    "import nibabel as nb\n",
    "inToken = \"Fear199\"\n",
    "nd = neurodata()\n",
    "print(nd.get_metadata(inToken)['dataset']['voxelres'].keys())\n",
    "inImg = imgDownload(inToken, resolution=5)\n",
    "imgWrite(inImg, \"./Fear199.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Method 1:\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import scipy.misc\n",
    "TokenName = 'Fear199.nii'\n",
    "img = nib.load(TokenName)\n",
    "\n",
    "## Convert into np array (or memmap in this case)\n",
    "data = img.get_data()\n",
    "print data.shape\n",
    "print type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Method 2:\n",
    "rawData = sitk.GetArrayFromImage(inImg)  ## convert to simpleITK image to normal numpy ndarray\n",
    "print type(rawData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, method 1 generates an array with shape (x, y, z) -- specifically, (540, 717, 1358).  The method 2 generates a numpy array with shape (z, y, x) -- specifically, (1358, 717, 540).  Since we want the first column to be z slices, the original method was granting me x-slices (hence the cigar-tube dimensions).\n",
    "\n",
    "In order to interconvert, we can either just use the rawData approach after directly calling from ndstore, or we can take our numpy array after loading from nibabel and use numpy's swapaxes method to just swap two of the dimensions (shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## if we have (i, j, k), we want (k, j, i)  (converts nibabel format to sitk format)\n",
    "new_im = newer_img.swapaxes(0,2) # just swap i and k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Generating raw TIFF slices.\n",
    "Now that I have appropiate coordinates, I generated a subset of TIFF slices to run the training module for the image classifier.  Using the script here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plane = 0;\n",
    "for plane in (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 100, 101, 102, 103, 104):\n",
    "    output = np.asarray(rawData[plane])\n",
    "    ## Save as TIFF for Ilastik\n",
    "    scipy.misc.toimage(output).save('RAWoutfile' + TokenName + 'ITK' + str(plane) + '.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, I generated data for the first 13 planes, and then some subset of planes from z = 100 to z = 104.  I then trained the classifier on this data.  Below I've included images of how I zoomed in to select individual points.  I followed the cell density counting "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
