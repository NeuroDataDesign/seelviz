{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From ndparse ilastik classifcation code\n",
    "## Adapted to fit our code\n",
    "## wip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os\n",
    "import numpy as np\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_objectify(predictions, threshold, min_size, max_size, remove_speckle=20):\n",
    "\n",
    "    # TODO handle 2D arrays\n",
    "    import scipy.ndimage.measurements\n",
    "    import mahotas\n",
    "\n",
    "    label = predictions > threshold\n",
    "\n",
    "    if remove_speckle > 0:\n",
    "        speckle, n = mahotas.label(label, np.ones((3, 3, 1), bool))\n",
    "        sizes = mahotas.labeled.labeled_size(speckle)\n",
    "        reject = np.where(sizes < remove_speckle)\n",
    "        label = mahotas.labeled.remove_regions(speckle, reject)\n",
    "        label = np.asarray(label > 0)\n",
    "\n",
    "    label = mahotas.label(label, np.ones((3, 3, 3), bool))[0]\n",
    "\n",
    "    sizes = mahotas.labeled.labeled_size(label)\n",
    "    reject = np.where((sizes < min_size) | (sizes > max_size))\n",
    "    label = mahotas.labeled.remove_regions(label, reject)\n",
    "    objects, n = mahotas.labeled.relabel(label)\n",
    "    print('After processing, there are {} objects left.'.format(n))\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ilastik_pixel(input_data, classifier, threads=2, ram=2000):\n",
    "\n",
    "    \"\"\"\n",
    "    Runs a pre-trained ilastik classifier on a volume of data\n",
    "    Adapted from Stuart Berg's example here:\n",
    "    https://github.com/ilastik/ilastik/blob/master/examples/example_python_client.py\n",
    "    Arguments:\n",
    "        input_data:  RAMONVolume containing a numpy array or raw numpy array\n",
    "    Returns:\n",
    "        pixel_out: The raw trained classifier\n",
    "    \"\"\"\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    import vigra\n",
    "    import os\n",
    "    import ilastik_main\n",
    "    from ilastik.applets.dataSelection import DatasetInfo\n",
    "    from ilastik.workflows.pixelClassification \\\n",
    "        import PixelClassificationWorkflow\n",
    "\n",
    "    # Before we start ilastik, prepare these environment variable settings.\n",
    "    os.environ[\"LAZYFLOW_THREADS\"] = str(threads)\n",
    "    os.environ[\"LAZYFLOW_TOTAL_RAM_MB\"] = str(ram)\n",
    "\n",
    "    # Set the command-line arguments directly into argparse.Namespace object\n",
    "    # Provide your project file, and don't forget to specify headless.\n",
    "    args = ilastik_main.parser.parse_args([])\n",
    "    args.headless = True\n",
    "    args.project = classifier\n",
    "\n",
    "    # Instantiate the 'shell', (an instance of ilastik.shell.HeadlessShell)\n",
    "    # This also loads the project file into shell.projectManager\n",
    "    shell = ilastik_main.main(args)\n",
    "    assert isinstance(shell.workflow, PixelClassificationWorkflow)\n",
    "\n",
    "    # Obtain the training operator\n",
    "    opPixelClassification = shell.workflow.pcApplet.topLevelOperator\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(opPixelClassification.InputImages) > 0\n",
    "    assert opPixelClassification.Classifier.ready()\n",
    "\n",
    "    # For this example, we'll use random input data to \"batch process\"\n",
    "    print input_data.shape\n",
    "\n",
    "    # In this example, we're using 2D data (extra dimension for channel).\n",
    "    # Tagging the data ensures that ilastik interprets the axes correctly.\n",
    "    input_data = vigra.taggedView(input_data, 'xyz')\n",
    "\n",
    "    # In case you're curious about which label class is which,\n",
    "    # let's read the label names from the project file.\n",
    "    label_names = opPixelClassification.LabelNames.value\n",
    "    label_colors = opPixelClassification.LabelColors.value\n",
    "    probability_colors = opPixelClassification.PmapColors.value\n",
    "\n",
    "    print label_names, label_colors, probability_colors\n",
    "\n",
    "    # Construct an OrderedDict of role-names -> DatasetInfos\n",
    "    # (See PixelClassificationWorkflow.ROLE_NAMES)\n",
    "    role_data_dict = OrderedDict([(\"Raw Data\",\n",
    "                                   [DatasetInfo(preloaded_array=input_data)])])\n",
    "\n",
    "    # Run the export via the BatchProcessingApplet\n",
    "    # Note: If you don't provide export_to_array, then the results will\n",
    "    #       be exported to disk according to project's DataExport settings.\n",
    "    #       In that case, run_export() returns None.\n",
    "    predictions = shell.workflow.batchProcessingApplet.\\\n",
    "        run_export(role_data_dict, export_to_array=True)\n",
    "    predictions = np.squeeze(predictions)\n",
    "    print predictions.dtype, predictions.shape\n",
    "\n",
    "    print \"DONE.\"\n",
    "\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
